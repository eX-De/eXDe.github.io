const messages = {
    en: {
        homepage:{
            nav: {
                language: 'ä¸­æ–‡'
            },
            anchor:{
                name: 'Wenbei Xie',
                nick_name: 'eX-De',
                school: 'Beijing University of Technology',
                clickCopy: 'Click to copy',
                menu: {
                    home: 'Home',
                    pub: 'Publications',
                    proj: 'Projects',
                    book: 'Bookshelf'
                }
            }
        },
        homesubpage:{
            intro:{
                hello: 'HiğŸ‘‹! Welcome to eX-De\'s personal homepage!',
                main1: 'I\'m currently an <b>4th grade undergraduate student</b> at <u>Beijing University of Technology</u> & <u>University College Dublin</u> who is majored in <b>Software Engineering</b> (2020-).During my university learning time, I have gained a comprehensive understanding of the whole subject area through the following courses.',
                coreCourseLearnt: 'Core Modules I Have Learned',
                main2: 'My research objective is to investigate and improve <b>inferential capability of language models</b>, especially Large Language Models. To make further progress on this objective, I believe it is necessary to apply our knowledge about <b>the procedure of human cognition</b> into the model design and development of other related techniques.',
                main3: 'As a 4th undergraduate student, I\'m currently looking for any opportunities of making research about <b>inferential capability of Large Language Models</b> in top universities around the world.'
            },
            tools:{
                title: 'Learned Skills & Tools'
            },
            selectProj:{
                label: 'Top Project',
                title: '<b>âœ¨AI Dailyâœ¨</b>',
                intro1: 'AI Daily is a knowledge-sharing account operated by myself. The aim of AI Daily is to share one AI-related knowledge point everyday.',
                intro2: 'âœ¨AI Daily 2023 Autumn Vol. is publishing nowâœ¨'
            },
            selectPaper:{
                label: 'Top Publication',
                title: '<b>A particular problem founded on the inferential capability of LLMs</b>',
                intro1: 'Writing now. Will be published on arXiv in Oct. 2023.',
            }
        },
        bookpage:{
            tab:{
                books: 'Books',
                papers: 'Papers',
                webpages: 'Webpages'
            },
            books:[
                {
                    title: 'Deep Learning From Scratch',
                    description: 'The Chinese version of this book helps me a lot on the basic concepts in the AI field. Strongly recommend for every beginners. Only Chinese and Japanese versions are available.',
                    link1_des: 'Japan Ver.',
                    link2_des: 'Chinese Ver.'
                },
                {
                    title: 'A Brief History of Artificial Intelligence',
                        description: 'When I first began to enter the field of artificial intelligence, in order to have a more systematic understanding of the field of artificial intelligence, I think it is necessary to find a book to explain the history of artificial intelligence. A relatively new book on the market at present is this Brief History of Artificial Intelligence by Nick.',
                    link1_des: 'Chinese Ver.',
                    link2_des: ''
                }
            ],
            papers:[
                {description: 'The goal of this paper is to give language models the ability to generate something like chains of thought - a series of coherent intermediate reasoning steps that lead to a final answer to a question.'},
                {description: 'This article proposes REMEMBERER, which can selectively leverage the experiences stored in memory to optimize decisions based on the current state of the interaction. At the same time, experiential memory can be constantly updated through reinforcement learning processes.'},
                {description: 'This paper makes small models (less than 100B parameters) perform better on inference tasks by fine-tuning away some of the general capabilities.'},
                {description: 'This post is a survey of the current challenges encountered in the field of LLMs.'},
                {description: 'This article points out that LLMs tend to ignore intermediate context.'}
            ],
            webs:[
                {
                    title: 'Towards Complex Reasoning: the Polaris of Large Language Models',
                    description: 'A roadmap towards building language models of strong reasoning capabilties. Covers the full development stages: pretraining, continue training, supervised finetuning, reinforcemeng learning, chain-of-thought prompting, and evaluation.'
                }
            ]
        }
    },
    zh: {
        homepage:{
            nav: {
                language: 'English'
            },
            anchor:{
                name: 'è°¢æ–‡è´',
                nick_name: 'eX-De',
                school: 'åŒ—äº¬å·¥ä¸šå¤§å­¦',
                clickCopy: 'ç‚¹å‡»å¤åˆ¶',
                menu: {
                    home: 'ä¸»é¡µ',
                    pub: 'è®ºæ–‡å’Œæ–‡ç« ',
                    proj: 'é¡¹ç›®',
                    book: 'ä¹¦æ¶'
                }
            }
        },
        homesubpage:{
            intro:{
                hello: 'HiğŸ‘‹! æ¬¢è¿æ¥åˆ°eX-Deçš„ä¸ªäººä¸»é¡µï¼',
                main1: 'æˆ‘ç›®å‰æ˜¯ä¸€åæ­£åœ¨å°±è¯»<u>åŒ—äº¬å·¥ä¸šå¤§å­¦</u>å’Œ<u>éƒ½æŸæ—å¤§å­¦å­¦é™¢</u>è”åˆå­¦å£«å­¦ä½çš„<b>å¤§å››</b>å­¦ç”Ÿã€‚æˆ‘çš„ä¸“ä¸šæ˜¯<b>è½¯ä»¶å·¥ç¨‹</b>ã€‚åœ¨æˆ‘çš„å¤§å­¦å­¦ä¹ ç”Ÿæ´»ä¸­ï¼Œæˆ‘é€šè¿‡å¦‚ä¸‹çš„è¯¾ç¨‹å¯¹æœ¬é¢†åŸŸçš„çŸ¥è¯†æœ‰äº†ä¸€å®šçš„ç†è§£ã€‚',
                coreCourseLearnt: 'æ ¸å¿ƒè¯¾ç¨‹åˆ—è¡¨',
                main2: 'æˆ‘çš„ç ”ç©¶ç›®æ ‡æ˜¯ç ”ç©¶å’Œæé«˜è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹çš„<b>æ¨ç†èƒ½åŠ›</b>ã€‚ä¸ºäº†åœ¨è¿™ä¸€ç›®æ ‡ä¸Šå–å¾—è¿›å±•ï¼Œæˆ‘è®¤ä¸ºæœ‰å¿…è¦å°†æˆ‘ä»¬å¯¹<b>äººç±»è®¤çŸ¥çš„è¿‡ç¨‹</b>çš„çŸ¥è¯†åº”ç”¨åˆ°æ¨¡å‹è®¾è®¡å’Œå…¶ä»–ç›¸å…³æŠ€æœ¯çš„ç ”å‘ä¸­ã€‚',
                main3: 'ä½œä¸ºå¤§å››çš„å­¦ç”Ÿï¼Œæˆ‘ç›®å‰æ­£åœ¨å¯»æ‰¾åœ¨ä¸–ç•Œå„åœ°çš„é¡¶å°–å¤§å­¦ä¸­ç ”ç©¶<b>å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</b>çš„æœºä¼šã€‚'
            },
            tools:{
                title: 'å­¦è¿‡çš„å·¥å…·å’ŒæŠ€æœ¯'
            },
            selectProj:{
                label: 'ç½®é¡¶é¡¹ç›®',
                title: '<b>âœ¨AI Dailyâœ¨</b>',
                intro1: 'AI Dailyæ˜¯ç”±æˆ‘ä¸ªäººè¿è¥çš„çŸ¥è¯†åˆ†äº«è´¦å·ï¼Œè‡´åŠ›äºæ¯å¤©åˆ†äº«ä¸€ä¸ªAIé¢†åŸŸçš„çŸ¥è¯†ç‚¹ã€‚',
                intro2: 'âœ¨ç›®å‰AI Daily 2023 ç§‹å­£ä¸“è¾‘æ­£åœ¨æ›´æ–°ä¸­âœ¨'
            },
            selectPaper:{
                label: 'ç½®é¡¶è®ºæ–‡',
                title: '<b>å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ€§èƒ½çš„æŸä¸ªé—®é¢˜</b>',
                intro1: 'æ­£åœ¨ä¹¦å†™ä¸­ï¼Œé¢„è®¡äº2023å¹´10æœˆä»½å‘è¡¨åœ¨arXivä¸Š',
            }
        },
        bookpage:{
            tab:{
                books: 'ä¹¦ç±å’Œæ–‡ç« ',
                papers: 'è®ºæ–‡',
                webpages: 'ç½‘é¡µ'
            },
            books:[
                {
                    title: 'æ·±åº¦å­¦ä¹ å…¥é—¨ï¼šåŸºäºPythonçš„ç†è®ºä¸å®ç°',
                    description: 'è¿™æœ¬ä¹¦å¸®åŠ©æˆ‘äº†è§£äº†å¾ˆå¤šAIé¢†åŸŸçš„åŸºç¡€çŸ¥è¯†ã€‚å®ƒç®€å•æ˜“æ‡‚ï¼Œå¾ªå¾ªå–„è¯±ï¼Œéå¸¸æ¨èåˆå­¦è€…é˜…è¯»ã€‚ç›®å‰åªæœ‰ä¸­æ–‡ç‰ˆå’Œè‹±æ–‡ç‰ˆã€‚',
                    link1_des: 'æ—¥æ–‡ç‰ˆ',
                    link2_des: 'ä¸­æ–‡ç‰ˆ'
                },
                {
                    title: 'äººå·¥æ™ºèƒ½ç®€å²',
                    description: 'åœ¨æˆ‘åˆšå¼€å§‹å…¥é—¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„æ—¶å€™ï¼Œä¸ºäº†å¯¹äººå·¥æ™ºèƒ½é¢†åŸŸæœ‰ä¸€ä¸ªæ¯”è¾ƒç³»ç»Ÿçš„è®¤è¯†ï¼Œæˆ‘è®¤ä¸ºæœ‰å¿…è¦æ‰¾åˆ°ä¸€æœ¬ä¹¦æ¥è®²è§£ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å²ã€‚ç›®å‰åœ¨å¸‚é¢ä¸Šæ¯”è¾ƒæ–°çš„ä¹¦å°±æ˜¯è¿™æœ¬ç”±å°¼å…‹æ‰€è‘—çš„ã€Šäººå·¥æ™ºèƒ½ç®€å²ã€‹ã€‚',
                    link1_des: 'ä¸­æ–‡ç‰ˆ',
                    link2_des: ''
                }
            ],
            papers:[
                {description: 'æœ¬æ–‡çš„ç›®æ ‡æ˜¯èµ‹äºˆè¯­è¨€æ¨¡å‹ç”Ÿæˆç±»ä¼¼æ€ç»´é“¾çš„èƒ½åŠ›â€”â€”ä¸€ç³»åˆ—è¿è´¯çš„ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œä»è€Œå¾—å‡ºé—®é¢˜çš„æœ€ç»ˆç­”æ¡ˆã€‚'},
                {description: 'æœ¬æ–‡æå‡ºäº†REMEMBERERï¼Œå®ƒå¯ä»¥æ ¹æ®å½“å‰äº¤äº’çŠ¶æ€é€‰æ‹©æ€§åœ°åˆ©ç”¨è®°å¿†ä¸­å­˜å‚¨çš„ç»éªŒæ¥ä¼˜åŒ–å†³ç­–ã€‚åŒæ—¶ï¼Œç»éªŒè®°å¿†å¯ä»¥é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸æ–­æ›´æ–°ã€‚'},
                {description: 'è¿™ç¯‡æ–‡ç« é€šè¿‡å¾®è°ƒæŠ›å¼ƒä¸€éƒ¨åˆ†é€šç”¨èƒ½åŠ›æ¥è®©å°å‹çš„æ¨¡å‹ï¼ˆå‚æ•°é‡å°äº100Bï¼‰ä¹Ÿèƒ½åœ¨æ¨ç†ä»»åŠ¡ä¸Šæœ‰æ›´å¥½çš„è¡¨ç°ã€‚'},
                {description: 'è¿™ç¯‡æ–‡ç« æ˜¯å¯¹ç›®å‰è¯­è¨€å¤§æ¨¡å‹é¢†åŸŸé‡åˆ°çš„æŒ‘æˆ˜çš„ä¸€ç¯‡ç»¼è¿°ã€‚'},
                {description: 'è¿™ç¯‡æ–‡ç« æŒ‡å‡ºäº†å¤§æ¨¡å‹ä¼šå€¾å‘äºå¿½ç•¥ä¸­é—´çš„ä¸Šä¸‹æ–‡ã€‚'}
            ],
            webs:[
                {
                    title: 'å¤æ‚æ¨ç†ï¼šå¤§è¯­è¨€æ¨¡å‹çš„åŒ—ææ˜Ÿèƒ½åŠ›',
                    description: 'æ„å»ºå…·æœ‰å¼ºå¤§æ¨ç†èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹çš„è·¯çº¿å›¾ã€‚æ¶µç›–äº†å®Œæ•´çš„å¼€å‘é˜¶æ®µ:é¢„è®­ç»ƒã€ç»§ç»­è®­ç»ƒã€æœ‰ç›‘ç£çš„å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ ã€æ€ç»´é“¾æç¤ºå’Œè¯„ä¼°ã€‚'
                }
            ]
        }
    }
}

export {
    messages
}