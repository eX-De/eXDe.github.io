const messages = {
    en: {
        homepage:{
            nav: {
                language: 'ä¸­æ–‡'
            },
            anchor:{
                name: 'Wenbei Xie',
                nick_name: 'eX-De',
                school: 'Beijing University of Technology',
                clickCopy: 'Click to copy',
                menu: {
                    home: 'Home',
                    pub: 'Publications',
                    proj: 'Projects',
                    book: 'Bookshelf'
                }
            }
        },
        homesubpage:{
            intro:{
                hello: 'HiğŸ‘‹! Welcome to eX-De\'s personal homepage!',
                main1: 'I\'m currently an <b>4th grade undergraduate student</b> at <u>Beijing University of Technology</u> & <u>University College Dublin</u> who is majored in <b>Software Engineering</b> (2020-).During my university learning time, I have gained a comprehensive understanding of the whole subject area through the following courses.',
                coreCourseLearnt: 'Core Modules I Have Learned',
                main2: 'My research objective is to investigate and improve <b>inferential capability of language models</b>, especially Large Language Models. To make further progress on this objective, I believe it is necessary to apply our knowledge about <b>the procedure of human cognition</b> into the model design and development of other related techniques.',
                main3: 'As a 4th undergraduate student, I\'m currently looking for any opportunities of making research about <b>inferential capability of Large Language Models</b> in top universities around the world.'
            },
            tools:{
                title: 'Learned Skills & Tools'
            },
            selectProj:{
                label: 'Top Project',
                title: '<b>âœ¨AI Dailyâœ¨</b>',
                intro1: 'AI Daily is a knowledge-sharing account operated by myself. The aim of AI Daily is to share one AI-related knowledge point everyday.',
                intro2: 'âœ¨AI Daily 2023 Autumn Vol. is publishing nowâœ¨'
            },
            selectPaper:{
                label: 'Top Publication',
                title: '<b>Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models</b>',
                intro1: 'Recent advancements in Large Language Models (LLMs) have demonstrated impressive capabilities across a range of natural language processing tasks, especially in reasoning, a cornerstone for achieving Artificial General Intelligence (AGI). However, commonly used benchmarks may not fully encapsulate the inferential abilities of these models in real-world scenarios. To address this gap, a new form of Question-Answering (QA) task, termed Reasoning with Redundant Information Provided (RRIP), is introduced. The study designed a modified version of the grade school math 8K (GSM-8K) dataset which has several variants focusing on different attributes of redundant information. This investigation evaluates two popular LLMs, LlaMA2-13B-chat and generative pre-trained transformer 3.5 (GPT-3.5), contrasting their performance on traditional QA tasks against the RRIP tasks. Findings indicate that while these models achieved moderate success on standard QA benchmarks, their performance notably declines when assessed on RRIP tasks. The study not only highlights the limitations of current LLMs in handling redundant information but also suggests that future training of these models should focus on incorporating redundant information into the training data to increase the performance on RRIP tasks.',
            }
        },
        bookpage:{
            tab:{
                books: 'Books',
                papers: 'Papers',
                webpages: 'Webpages'
            },
            books:[
                {
                    title: 'Deep Learning From Scratch',
                    description: 'The Chinese version of this book helps me a lot on the basic concepts in the AI field. Strongly recommend for every beginners. Only Chinese and Japanese versions are available.',
                    link1_des: 'Japanese Ver.',
                    link2_des: 'Chinese Ver.'
                },
                {
                    title: 'A Brief History of Artificial Intelligence',
                        description: 'When I first began to enter the field of artificial intelligence, in order to have a more systematic understanding of the field of artificial intelligence, I think it is necessary to find a book to explain the history of artificial intelligence. A relatively new book on the market at present is this Brief History of Artificial Intelligence by Nick.',
                    link1_des: 'Chinese Ver.',
                    link2_des: ''
                },
                {
                    title: 'The Foundations of Science: Science and Hypothesis, The Value of Science, Science and Method',
                    description: 'To start my career of doing research, I believe a set of methodology is needed to guide me on scientific research. This set of books written by Jules Henri PoincarÃ©, is a tetralogy of science philosophy. Some idea and thoughts of PoincarÃ© can be very helpful for us to form a better understanding on the spirit of science.',
                    link1_des: 'English Ver.',
                    link2_des: 'Chinese Ver.'
                },
                {
                    title: 'Elementary Mathematics from a Higher Standpoint',
                    description: 'I decided to study the advanced mathematics to form a solid foundation for doing research in Artificial Intelligence area. To find a better approach of learning mathematics and get to know the basic methodology of the development of math, I find this set of book to help me.',
                    link1_des: 'English Ver.',
                    link2_des: 'Chinese Ver.'
                },
                {
                    title: 'Mathematical Statistics: Basic Ideas and Selected Topics (2nd ed.)',
                    description: 'This is a great textbook for the beginners of statistics. The reason I chose this textbook for self-study is this book tells us the intuition of the mathematical concepts, and the reason of using these mathematical definitions, which is my primary standard of choosing math textbooks.',
                    link1_des: 'English Ver.',
                    link2_des: ''
                },
                {
                    title: 'Elementary Linear Algebra (12th ed., written by H. Anton, C. Rorres, A. Kaul)',
                    description: 'This is a great textbook for the beginners of Linear Algebra. The reason I chose this textbook for self-study is this book tells us the intuition of the mathematical concepts, and the reason of using these mathematical definitions, which is my primary standard of choosing math textbooks.',
                    link1_des: 'English Ver.',
                    link2_des: ''
                },
            ],
            papers:[
                {description: 'The goal of this paper is to give language models the ability to generate something like chains of thought - a series of coherent intermediate reasoning steps that lead to a final answer to a question.'},
                {description: 'This article proposes REMEMBERER, which can selectively leverage the experiences stored in memory to optimize decisions based on the current state of the interaction. At the same time, experiential memory can be constantly updated through reinforcement learning processes.'},
                {description: 'This paper makes small models (less than 100B parameters) perform better on inference tasks by fine-tuning away some of the general capabilities.'},
                {description: 'This post is a survey of the current challenges encountered in the field of LLMs.'},
                {description: 'This article points out that LLMs tend to ignore intermediate context.'}
            ],
            webs:[
                {
                    title: 'Towards Complex Reasoning: the Polaris of Large Language Models',
                    description: 'A roadmap towards building language models of strong reasoning capabilties. Covers the full development stages: pretraining, continue training, supervised finetuning, reinforcemeng learning, chain-of-thought prompting, and evaluation.'
                }
            ]
        }
    },
    zh: {
        homepage:{
            nav: {
                language: 'English'
            },
            anchor:{
                name: 'è°¢æ–‡è´',
                nick_name: 'eX-De',
                school: 'åŒ—äº¬å·¥ä¸šå¤§å­¦',
                clickCopy: 'ç‚¹å‡»å¤åˆ¶',
                menu: {
                    home: 'ä¸»é¡µ',
                    pub: 'è®ºæ–‡å’Œæ–‡ç« ',
                    proj: 'é¡¹ç›®',
                    book: 'ä¹¦æ¶'
                }
            }
        },
        homesubpage:{
            intro:{
                hello: 'HiğŸ‘‹! æ¬¢è¿æ¥åˆ°eX-Deçš„ä¸ªäººä¸»é¡µï¼',
                main1: 'æˆ‘ç›®å‰æ˜¯ä¸€åæ­£åœ¨å°±è¯»<u>åŒ—äº¬å·¥ä¸šå¤§å­¦</u>å’Œ<u>éƒ½æŸæ—å¤§å­¦å­¦é™¢</u>è”åˆå­¦å£«å­¦ä½çš„<b>å¤§å››</b>å­¦ç”Ÿã€‚æˆ‘çš„ä¸“ä¸šæ˜¯<b>è½¯ä»¶å·¥ç¨‹</b>ã€‚åœ¨æˆ‘çš„å¤§å­¦å­¦ä¹ ç”Ÿæ´»ä¸­ï¼Œæˆ‘é€šè¿‡å¦‚ä¸‹çš„è¯¾ç¨‹å¯¹æœ¬é¢†åŸŸçš„çŸ¥è¯†æœ‰äº†ä¸€å®šçš„ç†è§£ã€‚',
                coreCourseLearnt: 'æ ¸å¿ƒè¯¾ç¨‹åˆ—è¡¨',
                main2: 'æˆ‘çš„ç ”ç©¶ç›®æ ‡æ˜¯ç ”ç©¶å’Œæé«˜è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹çš„<b>æ¨ç†èƒ½åŠ›</b>ã€‚ä¸ºäº†åœ¨è¿™ä¸€ç›®æ ‡ä¸Šå–å¾—è¿›å±•ï¼Œæˆ‘è®¤ä¸ºæœ‰å¿…è¦å°†æˆ‘ä»¬å¯¹<b>äººç±»è®¤çŸ¥çš„è¿‡ç¨‹</b>çš„çŸ¥è¯†åº”ç”¨åˆ°æ¨¡å‹è®¾è®¡å’Œå…¶ä»–ç›¸å…³æŠ€æœ¯çš„ç ”å‘ä¸­ã€‚',
                main3: 'ä½œä¸ºå¤§å››çš„å­¦ç”Ÿï¼Œæˆ‘ç›®å‰æ­£åœ¨å¯»æ‰¾åœ¨ä¸–ç•Œå„åœ°çš„é¡¶å°–å¤§å­¦ä¸­ç ”ç©¶<b>å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</b>çš„æœºä¼šã€‚'
            },
            tools:{
                title: 'å­¦è¿‡çš„å·¥å…·å’ŒæŠ€æœ¯'
            },
            selectProj:{
                label: 'ç½®é¡¶é¡¹ç›®',
                title: '<b>âœ¨AI Dailyâœ¨</b>',
                intro1: 'AI Dailyæ˜¯ç”±æˆ‘ä¸ªäººè¿è¥çš„çŸ¥è¯†åˆ†äº«è´¦å·ï¼Œè‡´åŠ›äºæ¯å¤©åˆ†äº«ä¸€ä¸ªAIé¢†åŸŸçš„çŸ¥è¯†ç‚¹ã€‚',
                intro2: 'âœ¨ç›®å‰AI Daily 2023 ç§‹å­£ä¸“è¾‘æ­£åœ¨æ›´æ–°ä¸­âœ¨'
            },
            selectPaper:{
                label: 'ç½®é¡¶è®ºæ–‡',
                title: '<b>å¯¹å¤§è¯­è¨€æ¨¡å‹åŸºäºå†—ä½™ä¿¡æ¯æ¨ç†èƒ½åŠ›çš„åˆ†æ</b>',
                intro1: 'Recent advancements in Large Language Models (LLMs) have demonstrated impressive capabilities across a range of natural language processing tasks, especially in reasoning, a cornerstone for achieving Artificial General Intelligence (AGI). However, commonly used benchmarks may not fully encapsulate the inferential abilities of these models in real-world scenarios. To address this gap, a new form of Question-Answering (QA) task, termed Reasoning with Redundant Information Provided (RRIP), is introduced. The study designed a modified version of the grade school math 8K (GSM-8K) dataset which has several variants focusing on different attributes of redundant information. This investigation evaluates two popular LLMs, LlaMA2-13B-chat and generative pre-trained transformer 3.5 (GPT-3.5), contrasting their performance on traditional QA tasks against the RRIP tasks. Findings indicate that while these models achieved moderate success on standard QA benchmarks, their performance notably declines when assessed on RRIP tasks. The study not only highlights the limitations of current LLMs in handling redundant information but also suggests that future training of these models should focus on incorporating redundant information into the training data to increase the performance on RRIP tasks.',
            }
        },
        bookpage:{
            tab:{
                books: 'ä¹¦ç±å’Œæ–‡ç« ',
                papers: 'è®ºæ–‡',
                webpages: 'ç½‘é¡µ'
            },
            books:[
                {
                    title: 'æ·±åº¦å­¦ä¹ å…¥é—¨ï¼šåŸºäºPythonçš„ç†è®ºä¸å®ç°',
                    description: 'è¿™æœ¬ä¹¦å¸®åŠ©æˆ‘äº†è§£äº†å¾ˆå¤šAIé¢†åŸŸçš„åŸºç¡€çŸ¥è¯†ã€‚å®ƒç®€å•æ˜“æ‡‚ï¼Œå¾ªå¾ªå–„è¯±ï¼Œéå¸¸æ¨èåˆå­¦è€…é˜…è¯»ã€‚ç›®å‰åªæœ‰ä¸­æ–‡ç‰ˆå’Œè‹±æ–‡ç‰ˆã€‚',
                    link1_des: 'æ—¥æ–‡ç‰ˆ',
                    link2_des: 'ä¸­æ–‡ç‰ˆ'
                },
                {
                    title: 'äººå·¥æ™ºèƒ½ç®€å²',
                    description: 'åœ¨æˆ‘åˆšå¼€å§‹å…¥é—¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„æ—¶å€™ï¼Œä¸ºäº†å¯¹äººå·¥æ™ºèƒ½é¢†åŸŸæœ‰ä¸€ä¸ªæ¯”è¾ƒç³»ç»Ÿçš„è®¤è¯†ï¼Œæˆ‘è®¤ä¸ºæœ‰å¿…è¦æ‰¾åˆ°ä¸€æœ¬ä¹¦æ¥è®²è§£ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å²ã€‚ç›®å‰åœ¨å¸‚é¢ä¸Šæ¯”è¾ƒæ–°çš„ä¹¦å°±æ˜¯è¿™æœ¬ç”±å°¼å…‹æ‰€è‘—çš„ã€Šäººå·¥æ™ºèƒ½ç®€å²ã€‹ã€‚',
                    link1_des: 'ä¸­æ–‡ç‰ˆ',
                    link2_des: ''
                },
                {
                    title: 'åºåŠ è±ç§‘å­¦å“²å­¦å››éƒ¨æ›²ï¼šç§‘å­¦ä¸å‡è®¾ã€ç§‘å­¦ä¸æ–¹æ³•ã€ç§‘å­¦çš„ä»·å€¼ã€æœ€åçš„æ²‰æ€',
                    description: 'ä¸ºäº†å¼€å§‹æˆ‘çš„ç ”ç©¶ç”Ÿæ¶¯ï¼Œæˆ‘ç›¸ä¿¡æˆ‘éœ€è¦ä¸€å¥—æ–¹æ³•è®ºæ¥æŒ‡å¯¼æˆ‘çš„ç§‘ç ”ã€‚è¿™å¥—ä¹¦æ˜¯ç”±å„’å‹’Â·æ˜‚åˆ©Â·åºåŠ è±æ‰€ä½œçš„ç§‘å­¦å“²å­¦å››éƒ¨æ›²ã€‚æˆ‘ç›¸ä¿¡ä¹¦ä¸­çš„ä¸€äº›è§‚ç‚¹å’Œæ€æƒ³å¯¹æˆ‘ä»¬æ›´å¥½åœ°ç†è§£ç§‘å­¦ç²¾ç¥æ˜¯å¾ˆæœ‰å¸®åŠ©çš„ã€‚',
                    link1_des: 'è‹±æ–‡ç‰ˆ',
                    link2_des: 'ä¸­æ–‡ç‰ˆ'
                },
                {
                    title: 'é«˜è§‚ç‚¹ä¸‹çš„åˆç­‰æ•°å­¦',
                    description: 'æˆ‘æ‰“ç®—é‡æ–°è‡ªå­¦é«˜ç­‰æ•°å­¦ï¼Œä¸ºæœªæ¥æˆ‘è¿›è¡Œäººå·¥æ™ºèƒ½é¢†åŸŸçš„ç ”ç©¶æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚è¿™å¥—ä¹¦å¯ä»¥å¸®æˆ‘æ‰¾åˆ°ä¸€ç§æ›´å¥½çš„å­¦ä¹ æ•°å­¦çš„æ–¹æ³•ï¼Œäº†è§£æ•°å­¦å‘å±•çš„åŸºæœ¬æ–¹æ³•è®ºã€‚',
                    link1_des: 'è‹±æ–‡ç‰ˆ',
                    link2_des: 'ä¸­æ–‡ç‰ˆ'
                },
                {
                    title: 'æ•°ç†ç»Ÿè®¡ï¼šåŸºæœ¬æ€æƒ³ä¸é‡ç‚¹ä¸“é¢˜ï¼ˆç¬¬äºŒç‰ˆï¼‰',
                    description: 'å¯¹äºç»Ÿè®¡å­¦åˆå­¦è€…æ¥è¯´ï¼Œè¿™æ˜¯ä¸€æœ¬å¾ˆæ£’çš„æ•™ç§‘ä¹¦ã€‚æˆ‘é€‰æ‹©è¿™æœ¬æ•™ç§‘ä¹¦è¿›è¡Œè‡ªå­¦çš„åŸå› æ˜¯å› ä¸ºè¿™æœ¬ä¹¦å‘Šè¯‰äº†æˆ‘ä»¬æ•°å­¦å®¶å‘æ˜æ•°å­¦æ¦‚å¿µæ—¶çš„ç›´è§‰ï¼Œä»¥åŠæ•°å­¦å®¶ä»¬ä½¿ç”¨è¿™äº›æ•°å­¦å®šä¹‰çš„åŸå› ï¼Œè¿™æ˜¯æˆ‘é€‰æ‹©æ•°å­¦æ•™æçš„ä¸»è¦æ ‡å‡†ã€‚',
                    link1_des: 'è‹±æ–‡ç‰ˆ',
                    link2_des: ''
                },
                {
                    title: 'åˆç­‰çº¿æ€§ä»£æ•° (ç¬¬åäºŒç‰ˆ, ä½œè€…æ˜¯H. Anton, C. Rorres, A. Kaul)',
                    description: 'å¯¹äºçº¿æ€§ä»£æ•°åˆå­¦è€…æ¥è¯´ï¼Œè¿™æ˜¯ä¸€æœ¬å¾ˆæ£’çš„æ•™ç§‘ä¹¦ã€‚æˆ‘é€‰æ‹©è¿™æœ¬æ•™ç§‘ä¹¦è¿›è¡Œè‡ªå­¦çš„åŸå› æ˜¯å› ä¸ºè¿™æœ¬ä¹¦å‘Šè¯‰äº†æˆ‘ä»¬æ•°å­¦å®¶å‘æ˜æ•°å­¦æ¦‚å¿µæ—¶çš„ç›´è§‰ï¼Œä»¥åŠæ•°å­¦å®¶ä»¬ä½¿ç”¨è¿™äº›æ•°å­¦å®šä¹‰çš„åŸå› ï¼Œè¿™æ˜¯æˆ‘é€‰æ‹©æ•°å­¦æ•™æçš„ä¸»è¦æ ‡å‡†ã€‚',
                    link1_des: 'è‹±æ–‡ç‰ˆ',
                    link2_des: ''
                },
            ],
            papers:[
                {description: 'æœ¬æ–‡çš„ç›®æ ‡æ˜¯èµ‹äºˆè¯­è¨€æ¨¡å‹ç”Ÿæˆç±»ä¼¼æ€ç»´é“¾çš„èƒ½åŠ›â€”â€”ä¸€ç³»åˆ—è¿è´¯çš„ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œä»è€Œå¾—å‡ºé—®é¢˜çš„æœ€ç»ˆç­”æ¡ˆã€‚'},
                {description: 'æœ¬æ–‡æå‡ºäº†REMEMBERERï¼Œå®ƒå¯ä»¥æ ¹æ®å½“å‰äº¤äº’çŠ¶æ€é€‰æ‹©æ€§åœ°åˆ©ç”¨è®°å¿†ä¸­å­˜å‚¨çš„ç»éªŒæ¥ä¼˜åŒ–å†³ç­–ã€‚åŒæ—¶ï¼Œç»éªŒè®°å¿†å¯ä»¥é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸æ–­æ›´æ–°ã€‚'},
                {description: 'è¿™ç¯‡æ–‡ç« é€šè¿‡å¾®è°ƒæŠ›å¼ƒä¸€éƒ¨åˆ†é€šç”¨èƒ½åŠ›æ¥è®©å°å‹çš„æ¨¡å‹ï¼ˆå‚æ•°é‡å°äº100Bï¼‰ä¹Ÿèƒ½åœ¨æ¨ç†ä»»åŠ¡ä¸Šæœ‰æ›´å¥½çš„è¡¨ç°ã€‚'},
                {description: 'è¿™ç¯‡æ–‡ç« æ˜¯å¯¹ç›®å‰è¯­è¨€å¤§æ¨¡å‹é¢†åŸŸé‡åˆ°çš„æŒ‘æˆ˜çš„ä¸€ç¯‡ç»¼è¿°ã€‚'},
                {description: 'è¿™ç¯‡æ–‡ç« æŒ‡å‡ºäº†å¤§æ¨¡å‹ä¼šå€¾å‘äºå¿½ç•¥ä¸­é—´çš„ä¸Šä¸‹æ–‡ã€‚'}
            ],
            webs:[
                {
                    title: 'å¤æ‚æ¨ç†ï¼šå¤§è¯­è¨€æ¨¡å‹çš„åŒ—ææ˜Ÿèƒ½åŠ›',
                    description: 'æ„å»ºå…·æœ‰å¼ºå¤§æ¨ç†èƒ½åŠ›çš„è¯­è¨€æ¨¡å‹çš„è·¯çº¿å›¾ã€‚æ¶µç›–äº†å®Œæ•´çš„å¼€å‘é˜¶æ®µ:é¢„è®­ç»ƒã€ç»§ç»­è®­ç»ƒã€æœ‰ç›‘ç£çš„å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ ã€æ€ç»´é“¾æç¤ºå’Œè¯„ä¼°ã€‚'
                }
            ]
        }
    }
}

export {
    messages
}